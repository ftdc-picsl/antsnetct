from . import ants_helpers
from . import bids_helpers
from . import preprocessing
from . import system_helpers

from .system_helpers import PipelineError

import argparse
import json
import logging
import os
import shutil
import sys
import tempfile
import traceback

logger = logging.getLogger(__name__)

# Helps with CLI help formatting
class RawDefaultsHelpFormatter(
    argparse.RawTextHelpFormatter, argparse.ArgumentDefaultsHelpFormatter
):
    pass


def longitudinal_analysis():

    # Handle args with argparse
    parser = argparse.ArgumentParser(formatter_class=RawDefaultsHelpFormatter, add_help = False,
                                     description='''Longitudinal cortical thickness analysis with ANTsPyNet.

    The analysis level for longitudinal data is the subject. By default, all T1w images for a participant will be
    processed longitudinally. To process a specific subset of images for a participant, use the --participant-images option.

    ''')

    required_parser = parser.add_argument_group('required_parser arguments')
    required_parser.add_argument("--cross-sectional-dataset", help="BIDS derivatives dataset dir, containing the "
                                 "cross-sectional analysis", type=str, required=True)
    required_parser.add_argument("--output-dataset", help="Output BIDS dataset dir", type=str, required=True)
    required_parser.add_argument("--participant", "--participant-list", help="Participant to process", type=str)

    template_parser = parser.add_argument_group('Template arguments')
    template_parser.add_argument("--template-name", help="Template to use for registration, or 'none' to disable this step.",
                                 type=str, default='MNI152NLin2009cAsym')
    template_parser.add_argument("--template-res", help="Resolution of the template, eg '01', '02', etc. Note this is a "
                                 "templateflow index and not a physical spacing. If the selected template does not define "
                                 "multiple resolutions, this is ignored.", type=str, default='01')
    template_parser.add_argument("--template-cohort", help="Template cohort, only needed for templates that define multiple "
                                 "cohorts", type=str, default=None)
    template_parser.add_argument("--template-reg-quick", help="Do quick registration to the template", action='store_true')

    sst_parser = parser.add_argument_group('Single Subject Template arguments')
    sst_parser.add_argument("--sst-transform", help="SST transform, rigid or SyN", default='rigid')
    sst_parser.add_argument("--sst-iterations", help="Number of iterations for SST registration", type=int, default=4)
    sst_parser.add_argument("--sst-brain-extracted", help="Use brain-extracted images for SST refinement", action='store_true')
    sst_parser.add_argument("--sst-seg-denoised", help="Use denoised input to segment the SST. After SST construction, "
                            " we compute a 'pseudo-session' image to segment with antspynet. By default, the "
                            "minimally-processed session images are used. With this flag, use denoised session images",
                            action='store_true')

    segmentation_parser = parser.add_argument_group('Segmentation arguments - will be used for SST and session processing')
    segmentation_parser.add_argument("--segmentation-method", help="Segmentation method to use. Either 'atropos' or "
                                     "'none'. If atropos, probseg images from the segmentation dataset, if defined, or from "
                                     "deep_atropos will be used as priors for segmentation and bias correction. If no "
                                     "segmentation dataset is provided, a segmentation will be generated by antspynet.",
                                     type=str, default='atropos')
    segmentation_parser.add_argument("--atropos-n4-iterations", help="Number of iterations of atropos-n4",
                                     type=int, default=3)
    segmentation_parser.add_argument("--atropos-prior-weight", help="Prior weight for Atropos", type=float, default=0.25)

    thickness_parser = parser.add_argument_group('Thickness arguments for session processing')
    thickness_parser.add_argument("--thickness-iterations", help="Number of iterations for cortical thickness estimation. "
                                  "Set to 0 to skip thickness calculation", type=int, default=45)

    template_parser = parser.add_argument_group('Group template arguments')
    template_parser.add_argument("--template-name", help="Template to use for registration, or 'none' to disable this step.",
                                 type=str, default='MNI152NLin2009cAsym')
    template_parser.add_argument("--template-res", help="Resolution of the template, eg '01', '02', etc. Note this is a "
                                 "templateflow index and not a physical spacing. If the selected template does not define "
                                 "multiple resolutions, this is ignored.", type=str, default='01')
    template_parser.add_argument("--template-cohort", help="Template cohort, only needed for templates that define multiple "
                                 "cohorts", type=str, default=None)
    template_parser.add_argument("--template-reg-quick", help="Do quick registration to the template", action='store_true')

    optional_parser = parser.add_argument_group('optional_parser arguments')
    optional_parser.add_argument("-h", "--help", action="help", help="show this help message and exit")
    optional_parser.add_argument("--participant-images", help="Text file containing a list of participant images to process "
                                 "relative to the cross-sectional dataset. If not provided, all images for the participant "
                                 "will be processed.", type=str, default=None)
    optional_parser.add_argument("--keep-workdir", help="Copy working directory to output, for debugging purposes. Either "
                                 "'never', 'on_error', or 'always'.", type=str, default='on_error')
    optional_parser.add_argument("--verbose", help="Verbose output", action='store_true')

    args = parser.parse_args()

    system_helpers.set_verbose(args.verbose)

    # If the only arg is "--longitudinal", print help and exit
    if len(sys.argv) == 1:
        parser.print_help()
        sys.exit(1)

    if args.participant is None:
        raise ValueError('Participant must be defined')

    cx_ds = args.cross_sectional_dataset

    input_t1w_bids = ()

    if args.participant_images is not None:
        with open(args.participant_images, 'r') as f:
            t1w_relpaths = [line.strip() for line in f]
            for relpath in t1w_relpaths:
                if not os.path.exists(os.path.join(cx_ds, relpath)):
                    raise ValueError(f"Image {relpath} not found in cross-sectional dataset")
                input_t1w_bids.append(bids_helpers.BIDSImage(os.path.join(cx_ds, relpath)))
    else:
        input_t1w_bids = bids_helpers.find_participant_images(cx_ds, args.participant, 'anat', 'desc_preproc-T1w')

    # Check that the output dataset exists, and if not, create
    # Update dataset_description.json if needed

    # Check cross-sectional and output datasets are not the same - will cause too much confusion
    if os.realpath(args.cross_sectional_dataset) == os.realpath(args.output_dataset):
        raise PipelineError("Cross-sectional and output datasets cannot be the same")

    with tempfile.TemporaryDirectory(suffix=f"antsnetct_longitudinal_{args.participant}.tmpdir") as working_dir:
        try:

            # Output structure

            # output_dataset/dataset_description.json
            # output_dataset/sub-123456
            # output_dataset/sub-123456/anat - contains SST and transforms to group template
            # output_dataset/sub-123456/ses-MR1/anat - contains session-specific files
            # output_dataset/sub-123456/ses-MR2/anat - contains session-specific files

            # SST input images - filenames, not BIDSImage objects
            sst_input_t1w_denoised_normalized_images = ()
            sst_input_t1w_masks = ()

            for t1w in input_t1w_bids:
                # get the T1w image and mask, and reset their origins to the mask centroid

                input_t1w_denoised_image = t1w.get_path()

                seg = t1w.get_derivative_prefix() + '_seg-antsnetct_dseg.nii.gz'

                normalized = ants_helpers.normalize_intensity(input_t1w_denoised_image, seg, working_dir)

                input_t1w_mask = os.path.join(cx_ds, t1w.get_derivative_prefix() + 'desc-brain_mask.nii.gz')

                origin_fix = preprocessing.reset_origin_by_centroid(normalized, input_t1w_mask, working_dir)

                sst_input_t1w_denoised_normalized_images.append(origin_fix)

                sst_input_t1w_masks.append(preprocessing.reset_origin_by_centroid(input_t1w_mask, input_t1w_mask, working_dir))

            if args.sst_brain_extracted:
                # First round is rigid with whole-head images
                ants_helpers.build_sst(sst_input_t1w_denoised_normalized_images, working_dir, reg_transform='Rigid[0.1]')
                # Now get a common brain mask for all sessions

                # Warp brain mask back to the session spaces

                # Now rebuild the SST with the brain-extracted images

                # Register the original images to the SST - make final transforms
            else:
                # Use the original images for the SST
                ants_helpers.build_sst(sst_input_t1w_denoised_images, working_dir)

            # define a common brain mask for all sessions
            if args.sst_brain_extracted:
                sst_input_t1w_denoised_unified_mask_brains = ()
                # Use common brain mask to get input for updated SST
                for idx, t1w_denoised in enumerate(sst_input_t1w_denoised_normalized_images):
                    ants_helpers.apply_transform(t1w_denoised, sst_brain_mask, sst_output['inverse_warps'][idx], working_dir,
                                                 interpolation = 'GenericLabel')
                ants_helpers.build_sst(sst_input_t1w_denoised_unified_mask_brains, working_dir)

            # Register the original images to the SST - make final transforms

            if args.sst_seg_denoised:
                # warp the denoised whole-head images to the SST space
                # normalize and combine
                pass
            else:
                # Use the original preproc images
                # normalize and combine
                pass

            # Write SST to output directory
            sst_bids = bids_helpers.image_to_bids(sst, args.output_dataset,
                                                  os.path.join('sub-' + args.participant, 'anat', 'sub-' + args.participant +
                                                               '_desc-SST_T1w.nii.gz'))


            # Segment the SST

            # align the SST to the group template

            # for each session
                # Warp priors to the session space
                # Segment the session
                # Compute thickness
                # Warp thickness to SST space
                # Compute jacobian in SST space if applicable
                # Warp thickness to group space

        except Exception as e:
            logger.error(f"Caught {type(e)} during processing of {str(t1w_bids)}")
            # Print stack trace
            traceback.print_exc()
            debug_workdir = os.path.join(output_dataset, t1w_bids.get_derivative_rel_path_prefix() + "_workdir")
            if args.keep_workdir.lower() != 'never':
                logger.info("Saving working directory to " + debug_workdir)
                shutil.copytree(working_dir, debug_workdir)

